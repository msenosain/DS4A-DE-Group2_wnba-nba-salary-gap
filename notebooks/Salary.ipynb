{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273c4fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Using cached lxml-4.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Collecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.8/site-packages (from html5lib) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from html5lib) (0.5.1)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, lxml, html5lib, bs4\n",
      "Successfully installed beautifulsoup4-4.11.1 bs4-0.0.1 html5lib-1.1 lxml-4.9.0 soupsieve-2.3.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml bs4 html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "table_pagination_length = 14;\n",
    "year = \"2020\"\n",
    "base_url = \"http://www.espn.com/nba/salaries/_/year/\"+ year\n",
    "\n",
    "def get_request_url(page_num):\n",
    "    req_url = base_url + \"/seasontype/3\"\n",
    "    if(page_num) > 1:\n",
    "        req_url = base_url + \"/page/\"+str(page_num)+\"/seasontype/3\" \n",
    "    return req_url\n",
    "    \n",
    "def read_data(pagination_length, base_url):\n",
    "    scrapped_data = \"\"\n",
    "    for num in range (1, table_pagination_length + 1):\n",
    "        request_url = get_request_url(num)\n",
    "        #print(\"reading data from url :\", request_url)\n",
    "        r = requests.get(request_url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        page_content = soup.find_all('tr', {\"class\": [\"evenrow\",\"oddrow\"]})\n",
    "        for record in page_content:\n",
    "            data = \"\"\n",
    "            for row_data in record.find_all('td'):\n",
    "                data = data +\" \" + row_data.text\n",
    "            scrapped_data = scrapped_data + \"\\n\"+ data \n",
    "    print(scrapped_data)\n",
    "    return scrapped_data\n",
    "\n",
    "#def write_to_csv(data):\n",
    "    \n",
    "    \n",
    "                       \n",
    "def main():\n",
    "    read_data(table_pagination_length, base_url)\n",
    "  \n",
    "  \n",
    "# Using the special variable \n",
    "# __name__\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cbb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
